{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "845d0c80-c2e6-443d-8a57-48aa8785c5c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import DataFrame, functions as F, types as T, Window\n",
    "\n",
    "import builtins\n",
    "from datetime import datetime\n",
    "from typing import Optional, Dict, Union, List, Tuple, Any\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "from pyspark.ml.linalg import Vectors, DenseVector, SparseVector, VectorUDT\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidatorModel, TrainValidationSplitModel, ParamGridBuilder, CrossValidator, TrainValidationSplit\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql.functions import round "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d0a9c1b-67f7-4fbe-9235-1874ba48298f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90037fe1-5285-4e6e-86bc-14c75858948d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "LABEL_COL = \"churn3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcfe1b73-5173-4267-9afe-caaaa85d4d35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "FEATURES_TABLE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67e487eb-ec22-4b5f-9fbb-349136080d67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get data from table\n",
    "spark.sql(f\"select * from {FEATURES_TABLE_NAME}_clusters\").withColumn(\"label\",col(LABEL_COL)).createOrReplaceTempView(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "448bcdfc-1ab3-42ac-8a96-3cff75899388",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TEMP VIEW VO_EVAL AS\n",
    "SELECT * FROM dataset where DATE BETWEEN '2025-09-22'  AND '2025-10-13';\n",
    "\n",
    "CREATE OR REPLACE TEMP VIEW VO_TRAIN AS\n",
    "SELECT * FROM dataset where DATE BETWEEN DATE '2025-09-21' - INTERVAL 3 Months  AND '2025-09-21';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d015b73c-f7c3-437d-b219-3be7bdcb05db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "strat_train = spark.table(\"VO_TRAIN\")\n",
    "strat_val = spark.table(\"VO_EVAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "194b48b0-6186-485f-af52-662db2191448",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set ML Flow experiment\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fd52d49-9acf-4dca-8285-719da86f43f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# string_features = []\n",
    "# other_features = ['unique_levels_played', 'market_idx','dayofweek','rounds_played', 'avg_attempts', 'total_attempts', 'avg_moves', 'win_rate', 'assist_success_rate', 'unassist_success_rate', 'assist_rate', 'total_boosters_used', 'total_boosters_spent', 'used_boosters_rate', 'spend_boosters_rate', 'avg_difficulty_score', 'rate_hard_levels', 'rate_superhard_levels', 'min_room_id_int', 'max_room_id_int', 'daily_win_rate_ref', 'daily_avg_boosters_used_ref', 'daily_avg_boosters_spent_ref', 'attribution_source_cd_idx', 'country_cd_idx', 'payer_type_cd_idx', 'iap_lifetime_amt', 'days_since_install', 'days_since_last_purchase', 'ad_revenue_amt', 'iap_revenue_amt', 'session_qty', 'total_session_length_qty', 'avg_session_length', 'sessions_per_round', 'avg_population_wr_on_levels_played_today', 'avg_population_assisted_rate_today', 'avg_population_attempts_today', 'wr_diff_vs_population', 'attempts_diff_vs_population', 'assist_rate_diff_vs_population', 'active_days_l7d', 'total_rounds_l7d', 'avg_rounds_l7d', 'avg_win_rate_l7d', 'avg_attempts_l7d', 'boosters_used_l7d', 'boosters_spent_l7d', 'avg_used_boosters_rate_l7d', 'active_days_l14d', 'avg_rounds_l14d', 'avg_win_rate_l14d', 'std_rounds_l14d', 'std_win_rate_l14d', 'active_days_l30d', 'avg_rounds_l30d', 'rounds_trend_weekly', 'win_rate_trend_weekly', 'boosters_usage_trend_weekly', 'rounds_ratio_7d_vs_14_7d', 'frequency_ratio_7d_vs_14d', 'levels_progressed_l7d', 'levels_progressed_l14d', 'levels_progressed_l30d', 'days_on_current_max_level', 'level_diversity_ratio',] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "423701fb-c5c2-4d5f-be39-3551d11d59c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "string_features = []\n",
    "other_features = ['avg_rounds_l7d',\n",
    "    'active_days_l7d',\n",
    "    'avg_win_rate_l7d',\n",
    "    'avg_attempts_l7d',\n",
    "    'boosters_used_l7d',\n",
    "    'iap_lifetime_amt',\n",
    "    'ad_revenue_amt',\n",
    "    'levels_progressed_l7d',\n",
    "    'days_on_current_max_level',\n",
    "    'avg_session_length',\n",
    "    'days_since_install',\n",
    "    'days_since_last_purchase',\n",
    "    'session_qty',\n",
    "    'active_days_l14d',\n",
    "    'active_days_l30d',\n",
    "    'cluster_0',\n",
    "    'cluster_1',\n",
    "    'cluster_2',\n",
    "    'cluster_3',\n",
    "    'cluster_4',\n",
    "    'cluster_5',\n",
    "    'cluster_6',\n",
    "    'cluster_7',\n",
    "    'cluster_8',\n",
    "    'cluster_9',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46e68493-00ae-47c0-bac3-431688d3044b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_total = strat_train.count()\n",
    "train_churn = strat_train.filter(col('label') == 1).count()\n",
    "train_no_churn = train_total - train_churn\n",
    "\n",
    "churn_ratio = train_churn / train_total\n",
    "print(f\"Churn ratio en train: {churn_ratio:.2%}\")\n",
    "\n",
    "#Calcular pesos balanceados\n",
    "# Formula: weight = n_samples / (n_classes * n_samples_class)\n",
    "weight_churn = train_total / (2 * train_churn)\n",
    "weight_no_churn = train_total / (2 * train_no_churn)\n",
    "\n",
    "print(f\"Weight para churn=1: {weight_churn:.2f}\")\n",
    "print(f\"Weight para churn=0: {weight_no_churn:.2f}\")\n",
    "\n",
    "# 3. Agregar columna weight SOLO a train\n",
    "strat_train_weighted = strat_train.withColumn('weight', \n",
    "    when(col('label') == 1, weight_churn)\n",
    "    .otherwise(weight_no_churn)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18fc0208-6833-4435-8893-364acc7be824",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#### Logistic Regression Pipeline\n",
    "\n",
    "#Prepare Data\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "imputer = Imputer(inputCols=other_features, outputCols=other_features).setStrategy(\"mean\")\n",
    "assembler = VectorAssembler(inputCols=other_features, outputCol=\"features_raw\")\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\", withMean=True, withStd=True)\n",
    "\n",
    "\n",
    "# Add classifier\n",
    "eval_metrics = [\"auc\", \"aucpr\", \"logloss\"]\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    featuresCol='features',\n",
    "    labelCol='label',\n",
    "    family='binomial',\n",
    "    weightCol='weight'\n",
    ")\n",
    "\n",
    "\n",
    "lr_pipeline = Pipeline(stages=[imputer, assembler, scaler, lr])\n",
    "\n",
    "\n",
    "# lr_grid = (ParamGridBuilder()\n",
    "#     .addGrid(lr.regParam, [1e-5, 1e-4, 1e-3, 1e-2, 0.1]) \n",
    "#     .addGrid(lr.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "#     .addGrid(lr.maxIter, [100, 200])  \n",
    "#     .addGrid(lr.fitIntercept, [True, False]) \n",
    "#     .build())\n",
    "\n",
    "lr_grid = (ParamGridBuilder()\n",
    "    .addGrid(lr.regParam, [0.001]) \n",
    "    .addGrid(lr.elasticNetParam, [1.0])\n",
    "    .addGrid(lr.maxIter, [100])  \n",
    "    .addGrid(lr.fitIntercept, [True]) \n",
    "    .build())\n",
    "\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol='label',\n",
    "    metricName='areaUnderPR'  # Precision-Recall AUC\n",
    ")\n",
    "\n",
    "lr_cv = CrossValidator(\n",
    "    estimator=lr_pipeline,\n",
    "    estimatorParamMaps=lr_grid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=2,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "042976f8-2721-427a-b90e-3cc6681734f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Spark\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "\n",
    "# Data handling / mÃ©tricas\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "\n",
    "# VisualizaciÃ³n\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# mlflow.spark.autolog()\n",
    "\n",
    "# # Entrenamiento\n",
    "# lr_model = lr_cv.fit(strat_train_weighted.persist(StorageLevel.MEMORY_AND_DISK))\n",
    "# best_lr = lr_model.bestModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d26f362-51f2-4bfa-8cba-5c084813157f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"SPARKML_TEMP_DFS_PATH\"] = \"/Volumes/teams/data_science/model_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3db52710-6d21-4f7b-9429-32aad39886ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "with mlflow.start_run(run_name=\"logistic_regression_churn_mini\") as run:\n",
    "    # Entrenamiento\n",
    "    lr_model = lr_cv.fit(strat_train_weighted)\n",
    "    best_lr = lr_model.bestModel\n",
    "\n",
    "    # Loguear el modelo entrenado en MLflow\n",
    "    mlflow.spark.log_model(best_lr, artifact_path=\"model\")\n",
    "\n",
    "    # Predicciones\n",
    "    predictions = best_lr.transform(strat_val)\n",
    "\n",
    "    # Evaluaciones\n",
    "    evaluator_roc = BinaryClassificationEvaluator(labelCol=\"churn3\", rawPredictionCol=\"probability\", metricName=\"areaUnderROC\")\n",
    "    auc = evaluator_roc.evaluate(predictions)\n",
    "    mlflow.log_metric(\"auc_roc\", auc)\n",
    "\n",
    "    evaluator_pr = BinaryClassificationEvaluator(labelCol=\"churn3\", rawPredictionCol=\"probability\", metricName=\"areaUnderPR\")\n",
    "    auc_pr = evaluator_pr.evaluate(predictions)\n",
    "    mlflow.log_metric(\"auc_pr\", auc_pr)\n",
    "\n",
    "    # =======================================================\n",
    "    # 4. Extraer prob_churn del DenseVector\n",
    "    # =======================================================\n",
    "\n",
    "\n",
    "    @F.udf(DoubleType())\n",
    "    def extract_prob_churn(v):\n",
    "        if v is None:\n",
    "            return None\n",
    "        return float(v[1]) if isinstance(v, DenseVector) else float(v.values[1])\n",
    "\n",
    "    pred_with_prob = predictions.withColumn(\"prob_churn\", extract_prob_churn(F.col(\"probability\")))\n",
    "\n",
    "    pred_with_prob = predictions.withColumn(\"prob_churn\", extract_prob_churn(F.col(\"probability\")))\n",
    "\n",
    "    # =======================================================\n",
    "    # 5. Calcular mÃ©tricas\n",
    "    # =======================================================\n",
    "    # AUC ROC y AUC PR\n",
    "    evaluator_roc = BinaryClassificationEvaluator(labelCol=\"churn3\", rawPredictionCol=\"probability\", metricName=\"areaUnderROC\")\n",
    "    auc = evaluator_roc.evaluate(predictions)\n",
    "\n",
    "    evaluator_pr = BinaryClassificationEvaluator(labelCol=\"churn3\", rawPredictionCol=\"probability\", metricName=\"areaUnderPR\")\n",
    "    auc_pr = evaluator_pr.evaluate(predictions)\n",
    "\n",
    "    # TP, FP, FN, TN\n",
    "    tp = pred_with_prob.filter((F.col(\"churn3\") == 1) & (F.col(\"prediction\") == 1)).count()\n",
    "    fp = pred_with_prob.filter((F.col(\"churn3\") == 0) & (F.col(\"prediction\") == 1)).count()\n",
    "    fn = pred_with_prob.filter((F.col(\"churn3\") == 1) & (F.col(\"prediction\") == 0)).count()\n",
    "    tn = pred_with_prob.filter((F.col(\"churn3\") == 0) & (F.col(\"prediction\") == 0)).count()\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-9)\n",
    "    recall = tp / (tp + fn + 1e-9)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-9)\n",
    "\n",
    "    # LogLoss (usa la prob_churn)\n",
    "    pdf = pred_with_prob.select(\"churn3\", \"prob_churn\").toPandas()\n",
    "    logloss = log_loss(pdf[\"churn3\"], pdf[\"prob_churn\"])\n",
    "\n",
    "    # =======================================================\n",
    "    # 6. Matriz de confusiÃ³n (visual)\n",
    "    # =======================================================\n",
    "    cm = confusion_matrix(pdf[\"churn3\"], (pdf[\"prob_churn\"] >= 0.5).astype(int))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "                xticklabels=[\"Pred No Churn\", \"Pred Churn\"],\n",
    "                yticklabels=[\"Real No Churn\", \"Real Churn\"])\n",
    "    plt.title(\"Confusion Matrix (threshold=0.5)\")\n",
    "    plt.xlabel(\"PredicciÃ³n\")\n",
    "    plt.ylabel(\"Real\")\n",
    "\n",
    "    # =======================================================\n",
    "    # 7. Loguear todo dentro del mismo run activo\n",
    "    # =======================================================\n",
    "    mlflow.log_metric(\"auc_roc\", auc)\n",
    "    mlflow.log_metric(\"auc_pr\", auc_pr)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"log_loss\", logloss)\n",
    "    mlflow.log_figure(fig, \"confusion_matrix.png\")\n",
    "\n",
    "    print(f\"\"\"\n",
    "    ðŸ“Š MÃ©tricas en Test:\n",
    "    AUC ROC:   {auc:.4f}\n",
    "    AUC PR:    {auc_pr:.4f}\n",
    "    Precision: {precision:.4f}\n",
    "    Recall:    {recall:.4f}\n",
    "    F1-score:  {f1:.4f}\n",
    "    Accuracy:  {accuracy:.4f}\n",
    "    LogLoss:   {logloss:.4f}\n",
    "    \"\"\")\n",
    "\n",
    "    print(f\"âœ… Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55ff13d0-39ef-4f05-8c5a-a5a2d714c4f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "with mlflow.start_run(run_name=\"logistic_regression_churn_mini\") as run:\n",
    "    # Entrenamiento\n",
    "    lr_model = lr_cv.fit(strat_train_weighted)\n",
    "    best_lr = lr_model.bestModel\n",
    "\n",
    "    # Loguear el modelo entrenado en MLflow\n",
    "    mlflow.spark.log_model(best_lr, artifact_path=\"model\")\n",
    "\n",
    "    # Predicciones\n",
    "    predictions = best_lr.transform(strat_val)\n",
    "\n",
    "    # Evaluaciones\n",
    "    evaluator_roc = BinaryClassificationEvaluator(labelCol=\"churn3\", rawPredictionCol=\"probability\", metricName=\"areaUnderROC\")\n",
    "    auc = evaluator_roc.evaluate(predictions)\n",
    "    mlflow.log_metric(\"auc_roc\", auc)\n",
    "\n",
    "    evaluator_pr = BinaryClassificationEvaluator(labelCol=\"churn3\", rawPredictionCol=\"probability\", metricName=\"areaUnderPR\")\n",
    "    auc_pr = evaluator_pr.evaluate(predictions)\n",
    "    mlflow.log_metric(\"auc_pr\", auc_pr)\n",
    "\n",
    "    # =======================================================\n",
    "    # 4. Extraer prob_churn del DenseVector\n",
    "    # =======================================================\n",
    "\n",
    "\n",
    "    @F.udf(DoubleType())\n",
    "    def extract_prob_churn(v):\n",
    "        if v is None:\n",
    "            return None\n",
    "        return float(v[1]) if isinstance(v, DenseVector) else float(v.values[1])\n",
    "\n",
    "    pred_with_prob = predictions.withColumn(\"prob_churn\", extract_prob_churn(F.col(\"probability\")))\n",
    "\n",
    "    pred_with_prob = predictions.withColumn(\"prob_churn\", extract_prob_churn(F.col(\"probability\")))\n",
    "\n",
    "    # =======================================================\n",
    "    # 5. Calcular mÃ©tricas\n",
    "    # =======================================================\n",
    "    # AUC ROC y AUC PR\n",
    "    evaluator_roc = BinaryClassificationEvaluator(labelCol=\"churn3\", rawPredictionCol=\"probability\", metricName=\"areaUnderROC\")\n",
    "    auc = evaluator_roc.evaluate(predictions)\n",
    "\n",
    "    evaluator_pr = BinaryClassificationEvaluator(labelCol=\"churn3\", rawPredictionCol=\"probability\", metricName=\"areaUnderPR\")\n",
    "    auc_pr = evaluator_pr.evaluate(predictions)\n",
    "\n",
    "    # TP, FP, FN, TN\n",
    "    tp = pred_with_prob.filter((F.col(\"churn3\") == 1) & (F.col(\"prediction\") == 1)).count()\n",
    "    fp = pred_with_prob.filter((F.col(\"churn3\") == 0) & (F.col(\"prediction\") == 1)).count()\n",
    "    fn = pred_with_prob.filter((F.col(\"churn3\") == 1) & (F.col(\"prediction\") == 0)).count()\n",
    "    tn = pred_with_prob.filter((F.col(\"churn3\") == 0) & (F.col(\"prediction\") == 0)).count()\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-9)\n",
    "    recall = tp / (tp + fn + 1e-9)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-9)\n",
    "\n",
    "    # LogLoss (usa la prob_churn)\n",
    "    pdf = pred_with_prob.select(\"churn3\", \"prob_churn\").toPandas()\n",
    "    logloss = log_loss(pdf[\"churn3\"], pdf[\"prob_churn\"])\n",
    "\n",
    "    # =======================================================\n",
    "    # 6. Matriz de confusiÃ³n (visual)\n",
    "    # =======================================================\n",
    "    cm = confusion_matrix(pdf[\"churn3\"], (pdf[\"prob_churn\"] >= 0.5).astype(int))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "                xticklabels=[\"Pred No Churn\", \"Pred Churn\"],\n",
    "                yticklabels=[\"Real No Churn\", \"Real Churn\"])\n",
    "    plt.title(\"Confusion Matrix (threshold=0.5)\")\n",
    "    plt.xlabel(\"PredicciÃ³n\")\n",
    "    plt.ylabel(\"Real\")\n",
    "\n",
    "    # =======================================================\n",
    "    # 7. Loguear todo dentro del mismo run activo\n",
    "    # =======================================================\n",
    "    mlflow.log_metric(\"auc_roc\", auc)\n",
    "    mlflow.log_metric(\"auc_pr\", auc_pr)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"log_loss\", logloss)\n",
    "    mlflow.log_figure(fig, \"confusion_matrix.png\")\n",
    "\n",
    "    print(f\"\"\"\n",
    "    ðŸ“Š MÃ©tricas en Test:\n",
    "    AUC ROC:   {auc:.4f}\n",
    "    AUC PR:    {auc_pr:.4f}\n",
    "    Precision: {precision:.4f}\n",
    "    Recall:    {recall:.4f}\n",
    "    F1-score:  {f1:.4f}\n",
    "    Accuracy:  {accuracy:.4f}\n",
    "    LogLoss:   {logloss:.4f}\n",
    "    \"\"\")\n",
    "\n",
    "    print(f\"âœ… Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ab94b03-ce55-4274-816d-c30e934d3165",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ðŸ“Š MÃ©tricas en Test:\n",
    "    AUC ROC:   0.8855\n",
    "    AUC PR:    0.3079\n",
    "    Precision: 0.1469\n",
    "    Recall:    0.8019\n",
    "    F1-score:  0.2482\n",
    "    Accuracy:  0.8194\n",
    "    LogLoss:   0.4367\n",
    "\n",
    "     ðŸ“Š MÃ©tricas en Test:\n",
    "    AUC ROC:   0.8855\n",
    "    AUC PR:    0.3077\n",
    "    Precision: 0.1469\n",
    "    Recall:    0.8017\n",
    "    F1-score:  0.2483\n",
    "    Accuracy:  0.8195\n",
    "    LogLoss:   0.4365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a5e53c3-207d-48d7-b764-f3cfbbd9cf73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "\n",
    "# =======================================================\n",
    "# 6bis. Curvas ROC y PR\n",
    "# =======================================================\n",
    "\n",
    "# Obtener arrays reales y probabilidades\n",
    "y_true = pdf[\"churn3\"]\n",
    "y_score = pdf[\"prob_churn\"]\n",
    "\n",
    "# --- ROC Curve ---\n",
    "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig_roc, ax_roc = plt.subplots(figsize=(6,5))\n",
    "ax_roc.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"AUC = {roc_auc:.4f}\")\n",
    "ax_roc.plot([0, 1], [0, 1], color=\"navy\", lw=1, linestyle=\"--\")\n",
    "ax_roc.set_xlim([0.0, 1.0])\n",
    "ax_roc.set_ylim([0.0, 1.05])\n",
    "ax_roc.set_xlabel(\"False Positive Rate\")\n",
    "ax_roc.set_ylabel(\"True Positive Rate\")\n",
    "ax_roc.set_title(\"ROC Curve\")\n",
    "ax_roc.legend(loc=\"lower right\")\n",
    "\n",
    "# mlflow.log_figure(fig_roc, \"roc_curve.png\")\n",
    "\n",
    "\n",
    "# --- Precision-Recall Curve ---\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_true, y_score)\n",
    "pr_auc = auc(recall_vals, precision_vals)\n",
    "\n",
    "fig_pr, ax_pr = plt.subplots(figsize=(6,5))\n",
    "ax_pr.plot(recall_vals, precision_vals, color=\"purple\", lw=2, label=f\"AUC PR = {pr_auc:.4f}\")\n",
    "ax_pr.set_xlim([0.0, 1.0])\n",
    "ax_pr.set_ylim([0.0, 1.05])\n",
    "ax_pr.set_xlabel(\"Recall\")\n",
    "ax_pr.set_ylabel(\"Precision\")\n",
    "ax_pr.set_title(\"Precision-Recall Curve\")\n",
    "ax_pr.legend(loc=\"lower left\")\n",
    "\n",
    "# mlflow.log_figure(fig_pr, \"precision_recall_curve.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a74f36a-fc2f-4e91-9ef7-2b2760b65293",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # =======================================================\n",
    "# # 3. Predicciones sobre test\n",
    "# # =======================================================\n",
    "# predictions = best_lr.transform(strat_val)\n",
    "\n",
    "# # =======================================================\n",
    "# # 4. Extraer prob_churn del DenseVector\n",
    "# # =======================================================\n",
    "\n",
    "\n",
    "# @F.udf(DoubleType())\n",
    "# def extract_prob_churn(v):\n",
    "#     if v is None:\n",
    "#         return None\n",
    "#     return float(v[1]) if isinstance(v, DenseVector) else float(v.values[1])\n",
    "\n",
    "# pred_with_prob = predictions.withColumn(\"prob_churn\", extract_prob_churn(F.col(\"probability\")))\n",
    "\n",
    "# pred_with_prob = predictions.withColumn(\"prob_churn\", extract_prob_churn(F.col(\"probability\")))\n",
    "\n",
    "# # =======================================================\n",
    "# # 5. Calcular mÃ©tricas\n",
    "# # =======================================================\n",
    "# # AUC ROC y AUC PR\n",
    "# evaluator_roc = BinaryClassificationEvaluator(labelCol=\"churn3\", rawPredictionCol=\"probability\", metricName=\"areaUnderROC\")\n",
    "# auc = evaluator_roc.evaluate(predictions)\n",
    "\n",
    "# evaluator_pr = BinaryClassificationEvaluator(labelCol=\"churn3\", rawPredictionCol=\"probability\", metricName=\"areaUnderPR\")\n",
    "# auc_pr = evaluator_pr.evaluate(predictions)\n",
    "\n",
    "# # TP, FP, FN, TN\n",
    "# tp = pred_with_prob.filter((F.col(\"churn3\") == 1) & (F.col(\"prediction\") == 1)).count()\n",
    "# fp = pred_with_prob.filter((F.col(\"churn3\") == 0) & (F.col(\"prediction\") == 1)).count()\n",
    "# fn = pred_with_prob.filter((F.col(\"churn3\") == 1) & (F.col(\"prediction\") == 0)).count()\n",
    "# tn = pred_with_prob.filter((F.col(\"churn3\") == 0) & (F.col(\"prediction\") == 0)).count()\n",
    "\n",
    "# precision = tp / (tp + fp + 1e-9)\n",
    "# recall = tp / (tp + fn + 1e-9)\n",
    "# f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "# accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-9)\n",
    "\n",
    "# # LogLoss (usa la prob_churn)\n",
    "# pdf = pred_with_prob.select(\"churn3\", \"prob_churn\").toPandas()\n",
    "# logloss = log_loss(pdf[\"churn3\"], pdf[\"prob_churn\"])\n",
    "\n",
    "# # =======================================================\n",
    "# # 6. Matriz de confusiÃ³n (visual)\n",
    "# # =======================================================\n",
    "# cm = confusion_matrix(pdf[\"churn3\"], (pdf[\"prob_churn\"] >= 0.5).astype(int))\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(5,4))\n",
    "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "#             xticklabels=[\"Pred No Churn\", \"Pred Churn\"],\n",
    "#             yticklabels=[\"Real No Churn\", \"Real Churn\"])\n",
    "# plt.title(\"Confusion Matrix (threshold=0.5)\")\n",
    "# plt.xlabel(\"PredicciÃ³n\")\n",
    "# plt.ylabel(\"Real\")\n",
    "\n",
    "# # =======================================================\n",
    "# # 7. Loguear todo dentro del mismo run activo\n",
    "# # =======================================================\n",
    "# mlflow.log_metric(\"auc_roc\", auc)\n",
    "# mlflow.log_metric(\"auc_pr\", auc_pr)\n",
    "# mlflow.log_metric(\"precision\", precision)\n",
    "# mlflow.log_metric(\"recall\", recall)\n",
    "# mlflow.log_metric(\"f1_score\", f1)\n",
    "# mlflow.log_metric(\"accuracy\", accuracy)\n",
    "# mlflow.log_metric(\"log_loss\", logloss)\n",
    "# mlflow.log_figure(fig, \"confusion_matrix.png\")\n",
    "\n",
    "# print(f\"\"\"\n",
    "# ðŸ“Š MÃ©tricas en Test:\n",
    "# AUC ROC:   {auc:.4f}\n",
    "# AUC PR:    {auc_pr:.4f}\n",
    "# Precision: {precision:.4f}\n",
    "# Recall:    {recall:.4f}\n",
    "# F1-score:  {f1:.4f}\n",
    "# Accuracy:  {accuracy:.4f}\n",
    "# LogLoss:   {logloss:.4f}\n",
    "# \"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1670715711580029,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "logreg_gp_3months_v2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
